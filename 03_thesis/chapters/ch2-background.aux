\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\zref@newlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Background}{7}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {xchapter}{Background}{7}{chapter.2}\protected@file@percent }
\@writefile{lot}{\contentsline {xchapter}{Background}{7}{chapter.2}\protected@file@percent }
\newlabel{chap:background}{{2}{7}{Background}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Preliminaries}{7}{section.2.1}\protected@file@percent }
\newlabel{sec:preliminaries}{{2.1}{7}{Preliminaries}{section.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Notation}{7}{subsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Rotations and Poses}{7}{subsection.2.1.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Notation used for mathematical objects.\relax }}{8}{table.caption.9}\protected@file@percent }
\newlabel{tab:notation}{{2.1}{8}{Notation used for mathematical objects.\relax }{table.caption.9}{}}
\@gls@reference{acronym}{dof}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{8}}
\@writefile{toc}{\contentsline {subsubsection}{Rotation Matrices}{8}{section*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Rigid-body Matrices}{9}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}Frames}{9}{subsection.2.1.3}\protected@file@percent }
\@gls@reference{acronym}{ros}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{9}}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Main reference frames used in this work.\relax }}{9}{table.caption.12}\protected@file@percent }
\newlabel{tab:frames}{{2.2}{9}{Main reference frames used in this work.\relax }{table.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces short version}}{10}{figure.caption.13}\protected@file@percent }
\newlabel{fig:frames}{{2.1}{10}{short version}{figure.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Optimisation}{10}{section.2.2}\protected@file@percent }
\newlabel{sec:optimisation}{{2.2}{10}{Optimisation}{section.2.2}{}}
\@gls@reference{acronym}{ls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Linear Least Squares}{10}{subsection.2.2.1}\protected@file@percent }
\newlabel{eq:weighted-ls}{{2.7}{11}{Linear Least Squares}{equation.2.2.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{Solving the Problem}{11}{section*.14}\protected@file@percent }
\newlabel{eq:normal-equations}{{2.13}{12}{Solving the Problem}{equation.2.2.13}{}}
\newlabel{eq:hessian}{{2.14}{12}{Solving the Problem}{equation.2.2.14}{}}
\@gls@reference{acronym}{isam}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{12}}
\@writefile{toc}{\contentsline {subsubsection}{Probabilistic Interpretation}{12}{section*.15}\protected@file@percent }
\@gls@reference{acronym}{map}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{12}}
\newlabel{eq:gaussian-factor}{{2.16}{12}{Probabilistic Interpretation}{equation.2.2.16}{}}
\newlabel{eq:map}{{2.17}{12}{Probabilistic Interpretation}{equation.2.2.17}{}}
\newlabel{eq:map-sq}{{2.18}{13}{Probabilistic Interpretation}{equation.2.2.18}{}}
\newlabel{eq:factors}{{2.19}{13}{Probabilistic Interpretation}{equation.2.2.19}{}}
\@writefile{toc}{\contentsline {subsubsection}{Interpretations of the Hessian}{13}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Non-linear Least Squares}{14}{subsection.2.2.2}\protected@file@percent }
\@gls@reference{acronym}{nls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{14}}
\newlabel{eq:weighted-nls}{{2.22}{14}{Non-linear Least Squares}{equation.2.2.22}{}}
\@writefile{toc}{\contentsline {subsubsection}{Solving the Problem}{14}{section*.17}\protected@file@percent }
\newlabel{eq:linearisation}{{2.24}{14}{Solving the Problem}{equation.2.2.24}{}}
\newlabel{eq:linearised-nls}{{2.25}{14}{Solving the Problem}{equation.2.2.25}{}}
\newlabel{eq:update-rule}{{2.27}{14}{Solving the Problem}{equation.2.2.27}{}}
\@gls@reference{acronym}{gn}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@writefile{toc}{\contentsline {subsubsection}{Alternative Optimisation Approaches}{15}{section*.18}\protected@file@percent }
\newlabel{eq:gradient-descent-rule}{{2.28}{15}{Alternative Optimisation Approaches}{equation.2.2.28}{}}
\@gls@reference{acronym}{gd}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\@gls@reference{acronym}{sgd}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{15}}
\newlabel{eq:sgd-rule}{{2.29}{15}{Alternative Optimisation Approaches}{equation.2.2.29}{}}
\@writefile{toc}{\contentsline {subsubsection}{On the Interpretations of \gls {nls}}{15}{section*.19}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Main camera units used in this work. \textbf  {Left:} Intel \emph  {Realsense D435i} stereo and depth visual-inertial unit. Source: Intel. \textbf  {Right:} Sevensense \emph  {Core Research} multi-camera visual-inertial sensor (formerly \emph  {Alphasense Core}). Source: Sevensense.\relax }}{16}{figure.caption.20}\protected@file@percent }
\newlabel{fig:cameras}{{2.2}{16}{Main camera units used in this work. \textbf {Left:} Intel \emph {Realsense D435i} stereo and depth visual-inertial unit. Source: Intel. \textbf {Right:} Sevensense \emph {Core Research} multi-camera visual-inertial sensor (formerly \emph {Alphasense Core}). Source: Sevensense.\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Platforms and Sensors}{16}{section.2.3}\protected@file@percent }
\newlabel{sec:platforms-sensors}{{2.3}{16}{Platforms and Sensors}{section.2.3}{}}
\@gls@reference{acronym}{lidar}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Cameras}{16}{subsection.2.3.1}\protected@file@percent }
\@gls@reference{acronym}{isp}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{17}}
\@writefile{toc}{\contentsline {subsubsection}{Camera Projection Geometry}{17}{section*.21}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces The pinhole camera model $\mathbf  {\pi }\left ({_\mathtt  {S}} \mathbf  {p} , {_\mathtt  {M}} \mathbf  {p} \right )$ projects the 3D point ${_\mathtt  {M}} \mathbf  {p} $ in the map frame, to the image cordinates ${_\mathtt  {S}} \mathbf  {p} $, given the extrinsic matrix $\mathbf  {T}_{\mathtt  {M} \mathtt  {C}}$.\relax }}{18}{figure.caption.22}\protected@file@percent }
\newlabel{fig:pinhole-model}{{2.3}{18}{The pinhole camera model $\mathbf {\pi }\left (\point {p}{\Sensor }, \point {p}{\M }\right )$ projects the 3D point $\point {p}{\M }$ in the map frame, to the image cordinates $\point {p}{\Sensor }$, given the extrinsic matrix $\pose {\M }{\C }$.\relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {paragraph}{Step 1: Represent the Point in the Camera Frame}{18}{section*.23}\protected@file@percent }
\newlabel{eq:pinhole-extrinsics}{{2.30}{18}{Step 1: Represent the Point in the Camera Frame}{equation.2.3.30}{}}
\@writefile{toc}{\contentsline {paragraph}{Step 2: Pinhole Projection}{18}{section*.24}\protected@file@percent }
\newlabel{eq:pinhole-proj}{{2.31}{18}{Step 2: Pinhole Projection}{equation.2.3.31}{}}
\@writefile{toc}{\contentsline {paragraph}{Step 3: Normalise the Coordinates}{18}{section*.25}\protected@file@percent }
\newlabel{eq:pinhole-proj-norm}{{2.32}{19}{Step 3: Normalise the Coordinates}{equation.2.3.32}{}}
\@writefile{toc}{\contentsline {subsubsection}{Moving Back from Images to 3D}{19}{section*.26}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Step 1: De-normalisation}{19}{section*.27}\protected@file@percent }
\newlabel{eq:pinhole-backproj-norm}{{2.33}{19}{Step 1: De-normalisation}{equation.2.3.33}{}}
\@writefile{toc}{\contentsline {paragraph}{Step 2: Back-project}{19}{section*.28}\protected@file@percent }
\newlabel{eq:pinhole-backproj}{{2.34}{19}{Step 2: Back-project}{equation.2.3.34}{}}
\newlabel{eq:disparity-stereo}{{2.35}{19}{Step 2: Back-project}{equation.2.3.35}{}}
\@gls@reference{acronym}{tof}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\newlabel{eq:disparity:depth}{{2.36}{20}{Step 2: Back-project}{equation.2.3.36}{}}
\@writefile{toc}{\contentsline {paragraph}{Step 3: Back to World Frame}{20}{section*.29}\protected@file@percent }
\newlabel{eq:pinhole-backproj-extrinsics}{{2.37}{20}{Step 3: Back to World Frame}{equation.2.3.37}{}}
\@writefile{toc}{\contentsline {subsubsection}{Applications}{20}{section*.30}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Visual Localisation}{20}{section*.31}\protected@file@percent }
\@gls@reference{acronym}{pnp}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{20}}
\@writefile{toc}{\contentsline {paragraph}{Elevation Mapping}{20}{section*.33}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Self-supervision}{20}{section*.35}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces \emph  {Visual localisation} methods minimise the reprojection error the idealised projection of 3D points ${_\mathtt  {M}} \mathbf  {p} _{i}$ and image measurements ${_\mathtt  {S}} \mathbf  {z} _{i}$. We use these principles in Chapter~\ref  {chap:visual-localisation}.\relax }}{21}{figure.caption.32}\protected@file@percent }
\newlabel{fig:pinhole-application-localisation}{{2.4}{21}{\emph {Visual localisation} methods minimise the reprojection error the idealised projection of 3D points $\point {p}{\M }_{i}$ and image measurements $\point {z}{\Sensor }_{i}$. We use these principles in \chapref {chap:visual-localisation}.\relax }{figure.caption.32}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces \emph  {Elevation mapping} relies on the back-projected image points using stereo or depth information to ray-cast them onto a planar grid that encodes the point's height. This grid representation is used for local planning in Chapter~\ref  {chap:local-planning}. \relax }}{21}{figure.caption.34}\protected@file@percent }
\newlabel{fig:pinhole-application-elevation}{{2.5}{21}{\emph {Elevation mapping} relies on the back-projected image points using stereo or depth information to ray-cast them onto a planar grid that encodes the point's height. This grid representation is used for local planning in \chapref {chap:local-planning}. \relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {subsubsection}{Lens Distortion}{21}{section*.37}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces By integrating the robot's traversed path over time and projecting it onto past images, we can generate a \emph  {supervision signal} used to train models of terrain traversability, as will be shown in Chapter~\ref  {chap:traversability-learning}\relax }}{22}{figure.caption.36}\protected@file@percent }
\newlabel{fig:pinhole-application-selfsupervision}{{2.6}{22}{By integrating the robot's traversed path over time and projecting it onto past images, we can generate a \emph {supervision signal} used to train models of terrain traversability, as will be shown in \chapref {chap:traversability-learning}\relax }{figure.caption.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Fisheye lens distortion in the Sevensense Core Research sensor. \textbf  {Left:} Distorted output before fisheye correction, henceforth displaying curved trees. \textbf  {Right:} Undistorted image, correctly displaying the trees standing straight. The empty pixels (black) represent areas that are not observed in the original input; these are introduced to match the specified intrinsics after undistortion.\relax }}{22}{figure.caption.38}\protected@file@percent }
\newlabel{fig:fisheye-distortion}{{2.7}{22}{Fisheye lens distortion in the Sevensense Core Research sensor. \textbf {Left:} Distorted output before fisheye correction, henceforth displaying curved trees. \textbf {Right:} Undistorted image, correctly displaying the trees standing straight. The empty pixels (black) represent areas that are not observed in the original input; these are introduced to match the specified intrinsics after undistortion.\relax }{figure.caption.38}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}LiDAR}{22}{subsection.2.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces \glspl {lidar} relevant to this thesis. \textbf  {Left:} Velodyne \emph  {VLP-16} \gls {lidar}. \textbf  {Center:} RoboSense \emph  {BPearl}. \textbf  {Right:} Leica \emph  {RTC360} \gls {tls}.\relax }}{23}{figure.caption.39}\protected@file@percent }
\@gls@reference{acronym}{tls}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{23}}
\newlabel{fig:lidars}{{2.8}{23}{\glspl {lidar} relevant to this thesis. \textbf {Left:} Velodyne \emph {VLP-16} \gls {lidar}. \textbf {Center:} RoboSense \emph {BPearl}. \textbf {Right:} Leica \emph {RTC360} \gls {tls}.\relax }{figure.caption.39}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Proprioceptive Sensing}{23}{subsection.2.3.3}\protected@file@percent }
\@gls@reference{acronym}{imu}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{23}}
\@gls@reference{acronym}{urdf}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{24}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Legged Robots}{24}{subsection.2.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Algorithms for Robot Navigation}{24}{section.2.4}\protected@file@percent }
\newlabel{sec:algorithms-navigation}{{2.4}{24}{Algorithms for Robot Navigation}{section.2.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.3}{\ignorespaces Specifications of different commercial robotic platforms. ANYmal C is the main robot used in this thesis.\relax }}{25}{table.caption.40}\protected@file@percent }
\newlabel{tab:robot-comparison}{{2.3}{25}{Specifications of different commercial robotic platforms. ANYmal C is the main robot used in this thesis.\relax }{table.caption.41}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}State Estimation}{25}{subsection.2.4.1}\protected@file@percent }
\newlabel{sec:navigation-state-estimation}{{2.4.1}{25}{State Estimation}{subsection.2.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Modular robot navigation pipeline. We have highlighted in blue the main modules we are concerned with in this thesis. Please refer to Sec.~\ref  {sec:algorithms-navigation} for more details.\relax }}{26}{figure.caption.42}\protected@file@percent }
\newlabel{fig:navigation-pipeline}{{2.9}{26}{Modular robot navigation pipeline. We have highlighted in blue the main modules we are concerned with in this thesis. Please refer to \secref {sec:algorithms-navigation} for more details.\relax }{figure.caption.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Odometry vs localisation systems as explained in Sec.~\ref  {sec:navigation-state-estimation}. \textbf  {(a) Odometry:} It determines the robot's state, usually its pose in the inertial frame $\mathtt  {I}$ and the body velocity. \textbf  {(b) Localisation:} It is concerned with estimating a consistent pose of the robot with respect to a map in the frame $\mathtt  {M}$.\relax }}{26}{figure.caption.43}\protected@file@percent }
\newlabel{fig:navigation-state-estimation}{{2.10}{26}{Odometry vs localisation systems as explained in \secref {sec:navigation-state-estimation}. \textbf {(a) Odometry:} It determines the robot's state, usually its pose in the inertial frame $\I $ and the body velocity. \textbf {(b) Localisation:} It is concerned with estimating a consistent pose of the robot with respect to a map in the frame $\M $.\relax }{figure.caption.43}{}}
\@writefile{toc}{\contentsline {subsubsection}{Odometry}{26}{section*.44}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Localisation}{27}{section*.45}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Global and Local Mapping}{27}{section*.46}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Metric vs Topological:}{27}{section*.47}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{2D vs 2.5D vs 3D:}{28}{section*.48}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Sparse vs Dense:}{28}{section*.49}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Discrete vs Continuous:}{28}{section*.50}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Geometric vs Semantic:}{28}{section*.51}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Local Planning}{28}{subsection.2.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Local planning systems aim to reach a goal while avoiding obstacles. To achieve this, they use the traversability information encoded in the local map to find a safe path (white) used to determine the twist command which would allow the locomotion controller to follow it.\relax }}{29}{figure.caption.52}\protected@file@percent }
\newlabel{fig:navigation-local-planning}{{2.11}{29}{Local planning systems aim to reach a goal while avoiding obstacles. To achieve this, they use the traversability information encoded in the local map to find a safe path (white) used to determine the twist command which would allow the locomotion controller to follow it.\relax }{figure.caption.52}{}}
\@writefile{toc}{\contentsline {subsubsection}{Traversability}{29}{section*.53}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Motion Generation Strategies}{29}{section*.55}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Different approaches to determine the traversability score in a local map. \textbf  {(a) From geometry:} It is obtained from geometric features of the local map, such as surface normals. \textbf  {(b) From semantics:} By using semantic segmentation approaches, it is possible to determine what is traversable by assigning costs to different semantic classes. \textbf  {(c) From self-supervision:} It uses information that the robot generates itself from past trajectories or future predictions. \textbf  {(d) From anomalies:} It considers the visited places as traversable, and any out-of-distribution sample as untraversable. \textbf  {(e) From demonstrations:} It obtains a cost map from demonstrations in an inverse reinforcement learning fashion.\relax }}{30}{figure.caption.54}\protected@file@percent }
\newlabel{fig:background-traversability}{{2.12}{30}{Different approaches to determine the traversability score in a local map. \textbf {(a) From geometry:} It is obtained from geometric features of the local map, such as surface normals. \textbf {(b) From semantics:} By using semantic segmentation approaches, it is possible to determine what is traversable by assigning costs to different semantic classes. \textbf {(c) From self-supervision:} It uses information that the robot generates itself from past trajectories or future predictions. \textbf {(d) From anomalies:} It considers the visited places as traversable, and any out-of-distribution sample as untraversable. \textbf {(e) From demonstrations:} It obtains a cost map from demonstrations in an inverse reinforcement learning fashion.\relax }{figure.caption.54}{}}
\@writefile{toc}{\contentsline {paragraph}{Grid-based Local Planning:}{30}{section*.56}\protected@file@percent }
\@gls@reference{acronym}{fmm}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{30}}
\@writefile{toc}{\contentsline {paragraph}{Sampling-based Local Planning:}{30}{section*.57}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Optimisation-based Local Planning:}{30}{section*.58}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Motion Primitives:}{31}{section*.59}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Reactive Approaches:}{31}{section*.60}\protected@file@percent }
\@gls@reference{acronym}{apf}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{31}}
\@gls@reference{acronym}{rmp}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Locomotion Control}{31}{subsection.2.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Model-based Controllers:}{32}{section*.61}\protected@file@percent }
\@gls@reference{acronym}{to}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{32}}
\@gls@reference{acronym}{mpc}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{32}}
\@writefile{toc}{\contentsline {paragraph}{Reinforcement Learning-based Controllers:}{32}{section*.62}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.4}Mission Planning}{32}{subsection.2.4.4}\protected@file@percent }
\@gls@reference{acronym}{vtr}{\glsnoidxdisplayloc{}{page}{glsnumberformat}{33}}
\@setckpt{chapters/ch2-background}{
\setcounter{page}{34}
\setcounter{equation}{37}
\setcounter{enumi}{6}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{1}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{4}
\setcounter{subsection}{4}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{12}
\setcounter{table}{3}
\setcounter{parentequation}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{caption@flags}{0}
\setcounter{continuedfloat}{0}
\setcounter{r@tfl@t}{0}
\setcounter{AM@survey}{0}
\setcounter{@pps}{0}
\setcounter{@ppsavesec}{0}
\setcounter{@ppsaveapp}{0}
\setcounter{Item}{9}
\setcounter{Hfootnote}{1}
\setcounter{bookmark@seq@number}{27}
\setcounter{mtc}{3}
\setcounter{minitocdepth}{2}
\setcounter{ptc}{0}
\setcounter{parttocdepth}{2}
\setcounter{tabx@nest}{0}
\setcounter{listtotal}{0}
\setcounter{listcount}{0}
\setcounter{liststart}{0}
\setcounter{liststop}{0}
\setcounter{citecount}{0}
\setcounter{citetotal}{0}
\setcounter{multicitecount}{0}
\setcounter{multicitetotal}{0}
\setcounter{instcount}{0}
\setcounter{maxnames}{3}
\setcounter{minnames}{1}
\setcounter{maxitems}{3}
\setcounter{minitems}{1}
\setcounter{citecounter}{0}
\setcounter{maxcitecounter}{0}
\setcounter{savedcitecounter}{0}
\setcounter{uniquelist}{0}
\setcounter{uniquename}{0}
\setcounter{refsection}{0}
\setcounter{refsegment}{0}
\setcounter{maxextratitle}{0}
\setcounter{maxextratitleyear}{0}
\setcounter{maxextraname}{0}
\setcounter{maxextradate}{0}
\setcounter{maxextraalpha}{0}
\setcounter{abbrvpenalty}{500}
\setcounter{highnamepenalty}{500}
\setcounter{lownamepenalty}{250}
\setcounter{maxparens}{3}
\setcounter{parenlevel}{0}
\setcounter{mincomprange}{10}
\setcounter{maxcomprange}{100000}
\setcounter{mincompwidth}{1}
\setcounter{afterword}{0}
\setcounter{savedafterword}{0}
\setcounter{annotator}{0}
\setcounter{savedannotator}{0}
\setcounter{author}{0}
\setcounter{savedauthor}{0}
\setcounter{bookauthor}{0}
\setcounter{savedbookauthor}{0}
\setcounter{commentator}{0}
\setcounter{savedcommentator}{0}
\setcounter{editor}{0}
\setcounter{savededitor}{0}
\setcounter{editora}{0}
\setcounter{savededitora}{0}
\setcounter{editorb}{0}
\setcounter{savededitorb}{0}
\setcounter{editorc}{0}
\setcounter{savededitorc}{0}
\setcounter{foreword}{0}
\setcounter{savedforeword}{0}
\setcounter{holder}{0}
\setcounter{savedholder}{0}
\setcounter{introduction}{0}
\setcounter{savedintroduction}{0}
\setcounter{namea}{0}
\setcounter{savednamea}{0}
\setcounter{nameb}{0}
\setcounter{savednameb}{0}
\setcounter{namec}{0}
\setcounter{savednamec}{0}
\setcounter{translator}{0}
\setcounter{savedtranslator}{0}
\setcounter{shortauthor}{0}
\setcounter{savedshortauthor}{0}
\setcounter{shorteditor}{0}
\setcounter{savedshorteditor}{0}
\setcounter{labelname}{0}
\setcounter{savedlabelname}{0}
\setcounter{institution}{0}
\setcounter{savedinstitution}{0}
\setcounter{lista}{0}
\setcounter{savedlista}{0}
\setcounter{listb}{0}
\setcounter{savedlistb}{0}
\setcounter{listc}{0}
\setcounter{savedlistc}{0}
\setcounter{listd}{0}
\setcounter{savedlistd}{0}
\setcounter{liste}{0}
\setcounter{savedliste}{0}
\setcounter{listf}{0}
\setcounter{savedlistf}{0}
\setcounter{location}{0}
\setcounter{savedlocation}{0}
\setcounter{organization}{0}
\setcounter{savedorganization}{0}
\setcounter{origlocation}{0}
\setcounter{savedoriglocation}{0}
\setcounter{origpublisher}{0}
\setcounter{savedorigpublisher}{0}
\setcounter{publisher}{0}
\setcounter{savedpublisher}{0}
\setcounter{language}{0}
\setcounter{savedlanguage}{0}
\setcounter{origlanguage}{0}
\setcounter{savedoriglanguage}{0}
\setcounter{pageref}{0}
\setcounter{savedpageref}{0}
\setcounter{textcitecount}{0}
\setcounter{textcitetotal}{0}
\setcounter{textcitemaxnames}{0}
\setcounter{biburlbigbreakpenalty}{100}
\setcounter{biburlbreakpenalty}{200}
\setcounter{biburlnumpenalty}{0}
\setcounter{biburlucpenalty}{0}
\setcounter{biburllcpenalty}{0}
\setcounter{smartand}{1}
\setcounter{bbx:relatedcount}{0}
\setcounter{bbx:relatedtotal}{0}
\setcounter{su@anzahl}{0}
\setcounter{KVtest}{0}
\setcounter{subfigure}{0}
\setcounter{subfigure@save}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{subtable@save}{0}
\setcounter{lotdepth}{1}
\setcounter{@todonotes@numberoftodonotes}{0}
\setcounter{mdf@globalstyle@cnt}{0}
\setcounter{mdfcountframes}{0}
\setcounter{mdf@env@i}{0}
\setcounter{mdf@env@ii}{0}
\setcounter{mdf@zref@counter}{0}
\setcounter{section@level}{2}
\setcounter{minilofdepth}{2}
\setcounter{minilotdepth}{2}
\setcounter{partlofdepth}{2}
\setcounter{partlotdepth}{2}
\setcounter{sectlofdepth}{2}
\setcounter{sectlotdepth}{2}
}
