\chapter{Related Work}
\label{sec:related}

% PointNetVlad, Logg3dNet, EgoNN / ScanContext, STD  / Ransac, ICP, 
% Other papers to cite:
% Handcrafted: SegMap (Dube), M2DP (He)   
% ScanContext modifications: Intesity ScanContext, Semantic ScanContext (SSC) 
% Learned: Locus, Minkloc3d


% Paragraph 1: Overall Introduction
In this section, we first review different LiDAR-based place recognition methods. Specifically, we consider place recognition using a single LiDAR scan (\emph{single-shot localization}) scenario.
There are several methods designed for: \emph{Global Place Recognition Only} (only retrive most similar place based on descriptors), or \emph{Place Recogntion with Local Pose Estimation} (two stages process using both local features to estimate relative transformation and global features to retrive the most simillar place). In particular, we only focus on the latter methods, as relative 6-DoF transform between the matches is essential for integrating loop-closures within a SLAM system.  


Various LiDAR-based place recognition approaches exist on extracting descriptors: handcrafted models that extract geometric features and summary statistics \cite{kim2018iros, yuan2023icra}, and learning-based approaches that employ Convolutional Neural Networks (CNNs) and Transformers to compute high-level descriptors capable of distinguishing between different places \cite{vidanapathirana2022icra, komorowski2022ral}. Also, there are methods only consider global place recognition (retrive the most simillar place) and local pose estimation.
 
% \mfallon{also your framing is too narrow - you are talking about systems creating whole scan descriptors. Other methods work by matching segments/clusters.}
% \mfallon{SegMatch is a well cited handcrafted approach. And our own work called NSM (Georgi Tinchev) adapted it to natural environments.}
% \mfallon{SegMap and Georgi's follow up paper extended this approach to use learned descriptors.}
% \mfallon{so I think you should present (a) learned vrs handcrafted; and (b) whole scan vrs cluster based.}
% \haedam{Okay, I try to give an overview. Nived: Can you please check this ?}

% Paragraph 2: Place recognition models, hand crafted 
% ScanContext, Varients, STD
\subsection*{Handcrafted Descriptors} 
Among handcrafted approaches, ScanContext\cite{kim2018iros,kim2021tro} stands out as a widely adopted technique that generates a descriptor by encoding the point cloud as a bird’s-eye view representation. It captures height information within defined sectors and integrates them into a 2D descriptor. 
%The matching of these descriptors enables the estimation of translational and rotational differences between two corresponding point clouds.
ScanContext has also been enhanced by incorporating additional information such as intensity~\cite{wang2020icra} and semantics~\cite{li2021iros} to create more informative descriptors. 
Another type of handcrafted descriptor, STD~\cite{yuan2023icra}, encodes boundaries of planes as vertices and connects them to create multiple triangles. STD operates without requiring a 360-degree scan, making it compatible with LiDAR systems with a 90-degree field of view (e.g. Livox Aria). Both ScanContext and STD can estimate a relative transformation between corresponding scans by matching their descriptors, which is useful for loop closures candidates in SLAM or relocalization tasks. However, the previous methods have been primarily tested in urban scenarios. In this work we specifically aim to study their performance in unstructured, natural environments such as forests.
% \mfallon{you need to unravel this paragraph. it should be 1 ScanContext, 2 extensions of ScanContext and then 3 STD. At the moment it is all rolled together}
% \mfallon{you should cite ScanContext++ - extension by original authors.}
% \mfallon{BTW, the key feature of STD is that it works without needing a 360 scan. For example it works with a Livox Aria 90 degreee lidar.} 
% \haedam{rephrase the order of paragraph. Nived can you check this ?}

% Paragraph 3: Place recognition models, learning based 
\subsection*{Learning based Descriptors} 
Alternatively, recent learning-based models, such as Logg3dNet~\cite{vidanapathirana2022icra}, MinkLoc3D~\cite{komorowski2021wacv}, and EgoNN~\cite{komorowski2022ral} employ discretized representations and contrastive learning schemes to compute point-based local descriptors. This process is followed by generating a global descriptor of aggregated local features using methods like GeM~\cite{radenovic2019pami}, P2O~\cite{vidanapathirana2021icra}, and NetVLAD~\cite{arandjelovic2018pami}.  
% Add P2O high order pooling 
Particularly, Logg3dNet~\cite{vidanapathirana2022icra} uses a sparse convolutional network with both local consistency and global scene losses learned in a contrastive manner. Similarly, EgoNN~\cite{komorowski2022ral} employs a deep CNN architecture to extract local descriptors and key points through regression, subsequently aggregating them using GeM to form a global descriptor.
Both models facilitate relative transformation by matching local keypoints with RANSAC, which enables a finer resolution registration using ICP. 
While Transformer variants \cite{zhang2019cvpr, xia2021cvpr, zhou2021icra, xu2021transloc3d} are known for their ability to capture long-term dependencies, they have high computational costs and  often focus on global-level place recognition without explicitly estimate the relative transformation between candidates. 
% \mfallon{we need to talk about this - its still too abrupt}
% \mfallon{is the `inability to provide relative pose estimation' inherent in Transformer methods? If not your comment at the end is ill fitting. }
% \haedam{Haedam: Transformer models here only provide global-level place recognition not local-level pose estimation for those cited papers}

% \mfallon{please use `relative transformation' not `relative pose'. Pose is a transformation relative to a fixed coordinate frame (e.g. Odom,.}
% \haedam{Done}
\subsection*{Other Descriptors} 
As an alternative to a whole scan descriptor, some methods utilize segments to capture the important elements, effectively compressing the information in the entire point cloud map into a more compact representation. SegMatch \cite{dube2017icra} by Dubé et al. computes local segments and extracts geometric features as a descriptor. In their follow-up work, SegMap \cite{dube2018rss}, these features were learned via a CNN, showing improved overall performance. Tinchev et al. \cite{tinchev2018iros, tinchev2019ral} have applied the segment-based approach to natural environments, showing promising results. However, these methods are vulnerable when these segments cannot be reliably detected due to occlusions in dense forest environments, as well as long-term changes in the environment.


% Paragraph 4: Environmental forest data, benchmarking , SLAM system, Wildplace
\subsection*{Benchmark datasets} 
Several LiDAR point cloud datasets are available for benchmarking place recognition models in urban scenarios \cite{maddern2017ijrr, behley2019iccv, kim2020icra}. However, there are few datasets  for natural environments \cite{triest2022icra, knights2023icra}. In particular, the Wild-Places dataset \cite{knights2023icra} is tailored to large-scale place recognition in forests. This dataset provides point clouds and ground truth poses collected in a forest national park in Australia using hand-held spinning LiDAR at various times of the year. \\

In this paper, we assess the performance of four different place recognition models including both handcrafted (ScanContext and STD) and learning-based (Logg3dNet and EgoNN) models on our dense forest datasets collected across three different countries using a backpack LiDAR mapping device, in contrast to previous methods that often concentrated on access roads. 
% These datasets comprise both 32-beam narrow FOV (field-of-view) and 64-beam wide FOV setups . We then integrate these models into our SLAM system and evaluate their performance in identifying robust loop-closure pairs and providing accurate 6-DoF pose estimations within dense forest environments.  Our study focuses on loop-closure capability within dense forest areas, in contrast to previous methods that often concentrated on access roads. 


