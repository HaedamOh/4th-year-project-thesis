\chapter{Experiments}
\label{chapter:experiments} 

% \section{Experimental Evaluation Overview}\label{sec:exp}
In this section, we rigorously evaluate our place recognition pipeline to assess its performance in dense forest environments. Our evaluation includes four distinct test sites featuring varying forest compositions: Evo (Finland) is characterized by coniferous trees while Stein-Am-Rhein (Switzerland), Wytham Woods (UK) and Forest of Dean (UK) contain both broad-leaf and coniferous tree species. We evaluate all three operational modes of our system: Online SLAM, Offline Multi-Mission SLAM, and Relocalization.
% We can remove the summary of experiments to save space if needed
The experiments conducted are as follows:
\begin{enumerate}[label=\Roman*.]
  \listparindent=-20pt
  \item Evaluation of four different place recognition methods at the descriptor-level, tested across multiple forest environments with different LiDAR setups. (\secref{sec:exp_desc_analysis}) 
  \item Performance assessment during both online and offline SLAM operations within dense forest settings. (\secref{sec:exp_online_slam} \& \secref{sec:offline_multi_mission}).
  \item Analysis of successful loop closures, based on the baseline distance and orientation differences between the two candidate scans. (\secref{sec:exp_online_slam})
  \item Demonstration of the application of relocalization in a previously mapped forest environment, showcasing its utility in an inspection task performed by a quadruped robot. (\secref{sec:exp_relocalization})
\end{enumerate}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=\columnwidth]{pics/exp_0_missions_dataset.pdf}
  \caption{Illustrative examples of four forests used in the experiments. From top left to bottom right: Evo (Finland, May), Stein am Rhein (Switzerland, Sep), Wytham Woods (UK, Feb), and Forest of Dean (UK, March). The datasets were collected using backpack-carried LiDAR systems across different seasons and forest types.}
  \label{fig:missions_dataset}
\end{figure}


% First experiment: descriptors
\section{Place Recognition Descriptors}
\label{sec:exp_desc_analysis} 
In this experiment, we evaluated the descriptors of four different place recognition models (Logg3dNet, EgoNN, ScanContext, STD) focusing on their ability to accurately capture loop-candidates in forest environments. Logg3dNet and EgoNN models are learning-based methods, which were pre-trained on the Wild-Places dataset.

\begin{table}[htbp]
  \centering
  \caption{Summary statistics of evaluation datasets. Abbreviations used are as follows: Avg (Average),Desc (Descriptor evaluation), Online (Online SLAM), Offline (Offline multimission), Reloc. (Relocalization), Indiv. (Individual), Indiv.pc (Individual point clouds), tree density is roughly estimated by counting the average number of distinct trees within a \SI{7}{\meter} radius from the center of the sensor then scaled up to per hectare.} 
  \label{tab:eval_sequence}
  \small
  \centering
  \begin{tabular}{>{\centering\arraybackslash}m{1.5cm} >{\centering\arraybackslash}m{1.5cm} >{\centering\arraybackslash}m{1.5cm} >{\centering\arraybackslash}m{1.5cm} >{\centering\arraybackslash}m{1.5cm} >{\centering\arraybackslash}m{1.5cm} >{\centering\arraybackslash}m{1.5cm}>{\centering\arraybackslash}m{1.5cm}}
  \toprule
  \textbf{Dataset}  & \textbf{Eval Modes} &\textbf{Missions name} & \textbf{Avg. Mapping area(ha)} & \textbf{Avg. Duration (min)} & \textbf{Avg. \#Indiv. pc}  & \textbf{Avg. \#points per indiv.pc} & \textbf{Avg. \#trees per hectare} \\
  \midrule
  Stein am Rhein  & Desc. & exp03 & 0.27 ha & 13 min & 363 &  120k & 220  \\
  \midrule
  Wild-Place & Desc. & K-04 & Perimeter 3.17km  & 48 min & 5805 & 300k & 270 \\
  \midrule
  Evo  & Desc. Online. Offline. & exp16 exp18 & 0.74 ha   & 24 min & 969 &  110k  & 500 \\
  \midrule
  Wytham Woods & Desc. Online. Offline. & C D E F  & 1.2 ha & 22 min& 707 & 55k & 900 \\
  \midrule
  Forest of Deans & Online. Offline. Reloc. & exp01 exp02 exp03 & 0.45 ha  & 17 min & 649 & 50k & 130 \\
  \bottomrule
  \end{tabular}
\end{table}


\subsection*{Datasets} 
We collected the dataset with two different types of LiDAR sensors mounted on a backpack: Hesai XT32 and Hesai QT64  as discussed in previous \secref{sec:system_setup}. Note that Wild-Place\cite{knights2023icra} dataset was collected using an inclined VLP-16 LiDAR mounted on a continuously spinning motor. This enabled the capture of the canopy of the forest, which is difficult for our backpack LiDAR setup. In the following we summarize the characteristic of the different forests:
\begin{itemize}
  % \setlength\itemsep{-0.1em}
  \item \textbf{Stein am Rhein:} Stein am Rhein dataset was collected in a forest in Switzerland in October 2023. The dataset was collected using the Hesai XT32 LiDAR sensor. It displays mixed species and bushes with a low tree density.
  \item \textbf{Wild-Place:} Wild-Place dataset is open-source forest dataset which was collected by the Australian research team in forests in Australia over different seasons. The dataset was collected using a VLP-16 LiDAR sensor mounted on a spinning motor. The trajectories were along the open access roads and the forest canopy was captured. The dataset is characterized by a low tree density.
  \item \textbf{Evo:} Evo dataset was collected in forests in Finland. The dataset was collected in May 2023 using the Hesai XT32 LiDAR sensor. The forest is characterized by tall coniferous trees with medium tree density.
  \item \textbf{Wytham Woods:} Wytham Woods dataset was collected in a densely wooded area in the UK in February 2024. The dataset was collected using the Hesai QT64 LiDAR sensor. It is characterized by a high tree density and with complex terrains featuring hills and valleys.  
  \item \textbf{Forest of Dean:} Forest of Dean dataset was collected in a forest in the UK in March 2024. The dataset was collected using the Hesai QT64 LiDAR sensor. The dataset displays a sparser plantation with a low tree density.

\end{itemize}


\subsection*{Precision-Recall Curves}
Precision-recall curves (See \figref{fig:pr_curves}) show how accurately (precision) and frequently (recall) each  model detects correct loop candidates within a reasonable distance threshold (here set to 10\,m) at various descriptor thresholds $\tau_{s}$ in four different forests. Among positive candidates   (whose descriptor distance < $\tau_{s}$ ), we classify them into true positive (\emph{TP}) and false positive (\emph{FP}) depending on whether the candidate is actually located on their ground truth location within the loop-closure distance threshold, 10 meters. 
Similarly, among negative candidates, we classify them into true negative (\emph{TN}) and false negative (\emph{FN}) depending on their true location. 
\begin{equation}
  \small
  \text{Precision} = \frac{TP}{TP + FP} \quad \quad \text{Recall} = \frac{TP}{TP + FN} \quad \quad \text{F1} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
\end{equation}

From the precision-recall curves (\figref{fig:pr_curves}), it is evident that Logg3dNet consistently outperforms the other models across the four different forests. Particularly, on the Evo and Stein am Rhein datasets, where a longer range with narrow field-of-view Hesai XT32 LiDAR was employed, Logg3dNet showed the best performance both in terms of precision and recall, with a more gradual fall in precision and recall.
In contrast, ScanContext has much lower precision. This is because a limited vertical field-of-view of LiDAR sensor would produce inconsistent height values for descriptor bins depending on different viewpoints and descriptors not being translational invariant would lead to incorrect detection of the candidate. In more challenging scenarios such as Wytham Woods, handcrafted models show a notable decline in performance. Meanwhile, Logg3dNet remains robust, successfully retrieving a substantial portion of correct loop-candidates, achieving a 70\% precision at a 50\% recall rate. 
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.9\linewidth]{pics/exp_1.1_pr_curves}
  \caption{Precision-recall curves on four different forest datasets. Evo (Finland, May), Stein am Rhein (Switzerland, Oct), Wytham woods (UK, Feb), Wild-Places \cite{knights2023icra} (Australia).
  Evo and Stein am Rhein datasets were collected by Hesai XT32, and Wytham woods dataset was collected by Hesai QT64. Datasets were collected by backpack-carried LiDAR within dense forests. Only top-1 candidate within 10\,m of the ground truth position is regarded as a true positive candidate.}
  \label{fig:pr_curves}
\end{figure}
% \mfallon{I get to this bit and there is just a hole in the work because nothing about Logg3dNet's algorithm is ever discussed. There is no tuning or ablation. It just presented `as is'.}
\begin{figure}[t]
  \centering
  \includegraphics[width=0.85\linewidth]{pics/exp_1.2_heatmap_evo12_plasma_edit}
  \caption{The top right image shows the ground truth distance matrix, where each element represents the Euclidean distance between two poses. Yellow hues depict poses less than \SI{10}{\meter} apart, while farther poses are shown in purple shades. The remaining similarity matrices (heatmaps) depict the cosine distances between descriptors for the Evo dataset. Yellow hues indicate a high degree of similarity between descriptors of different scans, whereas purple shades represent low similarity. Patterns that more closely resemble the ground truth distance matrix (top-left) indicate better descriptor performance. The Logg3dNet descriptors exhibit patterns most similar to the ground truth, whereas the ScanContext descriptors are the least discriminative among these models. We use the value of $\tau_{s}$ that corresponds to the maximum $F_{1}$ score in the evaluation.}
  \label{fig:heatmap_evo12}
\end{figure}

\subsection*{Similarity matrix (heatmap)}
To further analyze the distinctiveness of each descriptor, we measured the descriptor distances between all query and database descriptors. This is shown in \figref{fig:heatmap_evo12} as a similarity matrix, which provides a visual representation of the discriminative potential of each descriptor. Consistent with the precision-recall curves, Logg3dNet descriptors exhibited higher similarity with the ground truth matrix as observed in the highlighted areas, indicating a high true-positive rate and low false-positive rate, respectively. This implies that Logg3dNet descriptors can effectively detect corresponding loop-candidates during revisits, whereas EgoNN and ScanContext tend to be less discriminative, often returning numerous false-positive candidates. Based on this evidence, we chose Logg3dNet as main the place recognition method for the rest of the experiments.





%%% Second experiment: Online SLAM
\section{Online Single Mission SLAM}
\label{sec:exp_online_slam}
In this experiment, we tested our complete pipeline (described in \secref{sec:pipeline}) and investigate its online place recognition capability, wherein loop closures from the place recognition module are integrated into VILNES SLAM system. First, illustrative results of loop closures obtained from different forest datasets are shown and discussed. Then, we further analyzed the loop closure statistics by distance and viewpoint differences. Lastly, we compared place recognition performance with handcrafted model, \emph{ScanContext}. 

\figref{fig:exp_2_1_evo_online} presents an illustrative example of online SLAM running on the Evo dataset sequence. In this mode, we can see loop closures (red lines) inside the dense forest between previous scans and the current scan. We can achieve these loop closures within the dense forest environment between previous scans and the current scan without having to revisit or retrace the previously traversed paths.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.9\columnwidth]{pics/exp_2_0_rviz2.pdf}
  \caption{Illustration of online SLAM mode running with the \emph{place recognition server} on the Evo exp16 sequence. Red lines are loop closures successfully captured by the place recognition module while mapping the forest (yellow trajectories).}
  \label{fig:exp_2_0_rviz}
\end{figure}



\subsection*{Online Place Recognition Results}
In this section we analyzed how the loop candidates are obtained and verified at each stage of the pipeline. To summarize typical performance, we analyzed each of three steps of the pipeline: candidate proposal, coarse registration, and fine registration. 
\begin{itemize}
  \item \textbf{Step 1: Loop candidate proposal (Blue)}\hspace{0.5em} Many loop closure candidates are initially proposed (shown with blue lines in \figref{fig:exp_2_1_evo_online} and \figref{fig:exp_2_1_wytham_online}) under a descriptor matching threshold $\tau_{s}$ of $F_{1}$-max score. Next, we simply use a fixed threshold of \SI{20}{\meter} and reject loop closures beyond this conservative estimate using the odometry information, assuming that the accumulated drift over such short traverses is relatively small compared to the \SI{20}{\meter} threshold. It is important to note that for much longer traverses where significant drift is expected, using the marginal covariance of the pose graph to reject statistically improbable loop closure candidates would be a more appropriate. Additionally, the database $D$ is incrementally built as the sensor moves through the environment, and the most recent 30 seconds of data are excluded to prevent loop closures with immediately recent measurements.
  
  \item \textbf{Step 2: Coarse Registration (Orange)}\hspace{0.5em} A subset of the initial loop closure candidates from Step 1 are identified using RANSAC feature matching (highlighted in orange lines in \figref{fig:exp_2_1_evo_online} and \figref{fig:exp_2_1_wytham_online}). These candidates are then verified using SGV and pairwise consistency checks. 

  \item \textbf{Step 3: Fine Registration (Red)}\hspace{0.5em} The loop closure candidates that pass the consistency and ICP (Iterative Closest Point) steps are integrated into the SLAM framework. The final loop closures (shown in red lines in \figref{fig:exp_2_1_evo_online} and \figref{fig:exp_2_1_wytham_online}) are the ICP verified loop candidates from Step 2. At this stage, we also reject any additional loop closures from similar positions to avoid over-constraining the pose graph (pose graph constraint density filter).
\end{itemize}
\textbf{Evo (\textbf{\figref{fig:exp_2_1_evo_online}})}\hspace{0.5em} We tested on Evo dataset as shown \figref{fig:exp_2_1_evo_online}. Evo16 sequence was densely scanned where each zigzag turn is about 10-15m apart, whereas Evo12 was mapped sparsely with about 20-30m apart. For Evo16, we can observe frequent loop candidates up to \SI{20}{\meter} between each zigzag turn, whereas for Evo12, fewer final loop closures were found than for Evo16. Initial candidates with an inter-pose distance above \SI{20}{\meter} are strongly rejected in the earlier stages of odometry estimate check and verification layers. In both experiments, we observe that the system can reliably detect loop closures inside the dense forest and correct the SLAM system's drift. \vspace{5pt}
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.53\columnwidth]{pics/exp_2_1_evo16_online2.png}
  \includegraphics[width=0.46\columnwidth]{pics/exp_2_1_evo12_online.png}
  \caption{Online SLAM results on Evo dataset. Evo16 (Left) and Evo12 (Right). Initial candidates (Blue) proposed by descriptor distance and odometry check. Yellow lines are RANSAC-registered candidates which have successfully passed SGV and pairwise consistency checks. Red lines are final loop closures after ICP verification and pose graph constraints density filter in pose graph.}
  \label{fig:exp_2_1_evo_online}
\end{figure}

\noindent \textbf{Wytham Woods (\textbf{\figref{fig:exp_2_1_wytham_online}})}\hspace{0.5em} We further tested on a more challenging dataset taken in Wytham Woods, which is a densely wooded area with uneven terrain, including hills. In \figref{fig:exp_2_1_wytham_online}, we demonstrate that a sufficiently large numbers of correct RANSAC-registered loop candidates, but ICP could not fine-register them. For example, regarding Mission D and C shown in \figref{fig:exp_2_1_wytham_online}, our system correctly detected loop candidates and RANSAC registered them (Yellow lines) at each turn. However, the ICP rejected almost all candidates. This was due to very small number of overlapping point clouds between two scans (usually 2k-3k out of 20k points, $\sim$\SI{10}{\percent} overlaps). Unfortunately, lowering ICP thresholds to less than $\sim$ 3k points to accept these candidates introduced false positives, resulting in a failure of system. In this dataset we see that our system suffers from a high rate of outliers due to occlusions and the large pose-to-pose translation at the far distance making ICP registration challenging. In summary, our system can correct drift in both sequences but is unable to find loop closures at the start.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.49\columnwidth]{pics/exp_2_1_wytham_D.png}
  \includegraphics[width=0.49\columnwidth]{pics/exp_2_1_wytham_C.png}
  \caption{Online SLAM results from Wytham Woods, two sequences Mission D(Left) and Mission C(Right) are shown. Light blue lines are initial candidates proposed by descriptor distance and odometry check. Yellow lines are successful RANSAC-registered candidates which passed the SGV and pairwise consistency checks. Red lines are final accepted loop closures after ICP verification and checking constraints density in pose graph. In both missions, ICP struggled to verify loop candidates from correctly RANSAC-registered due to the slow degree of overlap in the point clouds.}
  \label{fig:exp_2_1_wytham_online}
\end{figure}


\subsection*{Loop Closure Statistics}
% Present results in exp2_2
Alongside visual illustrations of loop closures, we conducted a comprehensive analysis of loop closure statistics based on distance and viewpoint angles, shown \figref{fig:exp_2_2_loop_closure_histograms}. Our findings show that the system can successfully identify loop closure pairs when there are considerable pose-to-pose baseline distances (\SIrange{10}{20}{\meter}). \vspace{5pt}
\begin{figure}[t]
  \centering
  \includegraphics[width=0.85\columnwidth]{pics/exp_2_2_loop_closure_histograms}
  \caption{Loop closures distribution by distance and angle at various stages of the pipeline on Evo dataset.
   Initial candidates based on descriptor distance are shown in blue. Candidates beyond \SI{20}{\meter} are rejected using odometry information. Candidates within \SI{20}{\meter} undergo RANSAC pre-registration with additional verification steps of SGV\cite{vidanapathirana2023ral} and pairwise checks (Yellow). Then these candidates are refined using ICP fine-registration (Red), and final loop closures in the pose graph after checking constraints density in pose graph (red with black outlined). Both of these categories count as success.}
  \label{fig:exp_2_2_loop_closure_histograms}
\end{figure}

\noindent \textbf{Baseline distance}\hspace{0.5em} We observed that despite the large baseline, a significant portion of initial candidates can be registered using RANSAC-based matching, indicating that the correspondences are accurate. However, the proportion of candidates verified by ICP decreases as the distance between scans increases. Specifically, when scans are \SI{10}{\meter} apart, $\sim$\SI{60}{\percent} of RANSAC-registered candidates are successfully verified by ICP, and when \SI{15}{\meter} apart, only $\sim$\SI{40}{\percent} remains verified. This decrease is due to the diminishing overlap ratio between corresponding scans with increasing distance, making the accurate convergence of ICP challenging. \vspace{5pt}

\noindent \textbf{Viewpoints difference}\hspace{0.5em} Similarly, regarding viewpoint orientation differences, we observed that a significant proportion of loop candidates, up to a \SI{90}{\degree} difference, were verified during the RANSAC-registration stage, constituting approximately  \SIrange{80}{50}{\percent} of the initial candidates. Subsequently, during ICP inliers checks, approximately \SIrange{80}{60}{\percent} of those RANSAC-registered candidates were finally verified. 

However, we observed a degradation in proportion of candidates beyond \SI{90}{\degree} to \SI{180}{\degree} at both the RANSAC-registration and ICP checks. The proportion of RANSAC-registered candidates decreased to below $\sim$\SI{30}{\percent} of the initial candidates, likely due to the rotational invariance limitations of the Logg3dNet descriptors. The proportion of ICP-verified candidates from RANSAC-registered candidates also declined to \SIrange{40}{10}{\percent}, which we assume is due to the small number of overlapping inlier points in the occluded point clouds captured from different viewpoints and locations.
Nonetheless, despite this degradation, the number of final loop closures integrated into the SLAM system proved to be sufficient for correcting the drift.   





\subsection*{Model Comparison: ScanContext}
So far we have shown capability of Logg3dNet reliably finding loop closures inside the forest. We now show how ScanContext performs (again integrated within  our SLAM system) to provide a comparison to Logg3dNet-based system. \figref{fig:exp_2_3_loop_closure_comparison} shows ScanContext's loop closure results on the Evo dataset. The figure can be directly compared with \figref{fig:exp_2_1_evo_online} (Left image) to see the difference in loop closure performance between Logg3dNet and ScanContext.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.75\columnwidth]{pics/exp_2_sc_loop_closure.png}
  % \includegraphics[width=0.49\columnwidth]{pics/exp_2_logg3dnet_loop_closure.png}
  \caption{Loop closures with ScanContext on Evo exp16 dataset. ScanContext could not detect any loop closures inside the dense forest but only in the open access road, whereas Logg3dNet successfully found loop closures inside the forest (as shown in previous \figref{fig:exp_2_1_evo_online}). Additionally, the ScanContext loops were only found within \SI{3}{\meter} (same location), whereas Logg3dNet detected loop closures up to \SI{15}{\meter}. Because of this the Scancontext-enabled SLAM system accumulates drift over time.}
  \label{fig:exp_2_3_loop_closure_comparison}
\end{figure}
From \figref{fig:exp_2_3_loop_closure_comparison}, we can observe that ScanContext could not detect any loop closures inside the dense forest producing a very high number of false positives (shown in blue lines), and could only achieve successful loop closures in the open access roads(red lines at the bottom of the plot). Among those loop closures along open access roads, ScanContext detected only within \SI{3}{\meter} (same location). Finally, ScanContext accumulated drift over time while Logg3dNet corrected this drift. This demonstrates the very limited capability of ScanContext compared to Logg3dnet, and this experiment validates the robustness of Logg3dNet compared to ScanContext (handcrafted method) in dense forest environments.
It was evident ScanContext shows a drop in performance in \ref{sec:exp_desc_analysis}, and now we evaluate if ScanContext can detect any loop candidates and find 6DoF transformation reliably inside the forest.  


% Third experiment: Offline Multi-Mission SLAM
%%% 
\section{Offline Multi-Mission SLAM} 
\label{sec:offline_multi_mission}
In this experiment, we showcased the ability of our approach to obtain loop closures between different mapping missions (e.g taken on different days) and to merge those missions into a common map. Below shows the results of merging different sequences within three different datasets: Wytham Woods, Evo, and the Forest of Dean. Each individual mission covers approximately one hectare, with merged map areas ranging from three to five hectares. 
\vspace{5pt}

\noindent \textbf{Evo (\figref{fig:exp_multi_mission_evo})}\hspace{0.5em}  Evo forest primarily comprises tall, mature coniferous trees. We mapped a total of 6 missions in the main site and successfully merged them. In particular, we tested the robustness of our system by placing XT32 LiDAR at a \SI{45}{\degree} inclination aimed at more densely capturing the forest canopy. Despite the asymmetry in point clouds introduced by this inclination change, which primarily captured points in the forward direction, our approach successfully identified loop closures and achieved multi-mission map merging.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=\columnwidth]{pics/exp_3_offline_evo_pcd.png}
  % \caption{Offline multi-mission SLAM point clouds output.}
  \includegraphics[width=\columnwidth]{pics/exp_3_1_multimission_slam_evo_ratio.png}
  \caption{Offline multi-mission SLAM (Evo). Merged point clouds (top) show successful loop closures between different missions. Inter-mission loop closures(bottom) identified when viewpoints are closely aligned. This is due to the \SI{45}{\degree} inclination of the LiDAR used in the main test site of Evo. }
  \label{fig:exp_multi_mission_evo}
\end{figure}
\vspace{5pt}

\noindent \textbf{Wytham Woods (\figref{fig:exp_multi_mission_wytham})} \hspace{0.5em}  Wytham Woods are the most challenging due to having the highest tree density, as well as the foliage, and vegetation present. Four multi-missions were captured with wide field-of-view Hesai QT64 LiDAR. Despite the challenges of the test site, our system successfully identified loop closures between different missions and merged them as shown in \figref{fig:exp_multi_mission_wytham}. During individual mission processing, slight odometry drift was noted in the SLAM system both at the beginning and end of each mission. However, during the multi-mission map merging process, the system successfully corrected this drift occurring in overlapping areas. 
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.9\columnwidth]{pics/exp_3_offline_wytham_pcd.png}
  % \caption{Wytam Woods: Offline multi-mission SLAM pointclouds}
  \includegraphics[width=0.9\columnwidth]{pics/exp_3_1_multimission_slam_wytham_ratio.png}
  \caption{Offline multi-mission SLAM (Wytham Woods). Merged point clouds map(top) shows successful loop closures (bottom) between the different missions in a densely wooded area with high tree density.}
  \label{fig:exp_multi_mission_wytham}
\end{figure}
\vspace{5pt}

\noindent \textbf{Forest of Dean (\figref{fig:exp_multi_mission_dean})}\hspace{0.5em} Forest of Dean is the least dense forest and a total of 3 missions collected there were merged easily. We observed that there were more frequent \emph{intermission} loop closures in the Forest of Dean compared to Wytham in overlapping areas. This is because more widely spread tree locations and minimal foliage produced much fewer occlusions and cleaner point clouds with higher number of overlapping points between two intermission scans. This favorable environment of Forest of Dean makes multi-mission map merging process easier when registering point clouds during the RANSAC-registration and ICP steps of loop candidates.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=\columnwidth]{pics/exp_3_offline_Dean_pcd3.png}
  % \caption{Forest of Dean: Offline multi-mission SLAM pointclouds}
  \includegraphics[width=\columnwidth]{pics/exp_3_1_multimission_slam_dean_ratio.png}
  \caption{Offline multi-mission SLAM(Forest of Dean). The merged map (top) shows successful loop closures (bottom) between the different missions. This plantation is much sparser than the others.}
  \label{fig:exp_multi_mission_dean}
\end{figure}
\vspace{5pt}

\noindent\textbf{Merged map quality (\figref{fig:truk_of_trees})}\hspace{0.5em} The quality of the merged maps were examined by checking point clouds of trees. We observed distinct tree trunks has no apparent signs of drift. The circular shapes of tree trunks were clearly seen in the point clouds, indicating that the map scanned in different positions were registered correctly. 
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.49\columnwidth]{pics/exp_3_offline_pointclouds_trunk.png}
  % \caption{A region of Evo merged forest map point clouds coloured by height. I cropped canopies to check trunks of trees. Trunks are very distinct showing no evidence of drift occured.}
  \includegraphics[width=0.49\columnwidth]{pics/exp_3_offline_pointclouds_trunk_BV3.png}
  \caption{Merged map quality. Trunks of trees from a bird's-eye view (right image). We observed the circular shapes of tree trunks clearly seen in the point clouds, indicating the map scanned in different viewpoints were registered correctly.}
  \label{fig:truk_of_trees}
\end{figure}

Overall, our experiments showed a potential capability for efficient large-scale mapping without any specific condition as to the route take. In particular, we did not need to start at the open access roads nor follow exactly the same paths to achieve loop closures between inter-missions. 


% \tabref{tab:exp_offline_distance_table} provides summary statistics of the distribution of loop closures at different distance ranges. Our multi-stage verification pipeline effectively filters out unreliable loop candidates, with approximately 90\% of successful candidates found within 10\,m of each other. Notably, experiments conducted in Wytham Woods and the Forest of Dean highlight that our system can identify loop closures within the forests, eliminating the need to precisely retrace previously mapped areas to achieve loop closures. This underscores the versatility and robustness of our approach in real-world forest mapping scenarios.


% \begin{figure*}[htbp]
%   \centering
%   \includegraphics[width=0.90\columnwidth]{pics/exp_3_1_multimission_slam_wytham.png}
%   \includegraphics[width=0.90\columnwidth]{pics/exp_3_1_multimission_slam_evo.png}
%   \includegraphics[width=0.90\columnwidth]{pics/exp_3_1_multimission_slam_dean.png}
%   \caption{Offline multi-mission SLAM. Left: Wytham - a densely wooded area with uneven terrain, including hills. Center: Evo - featuring a LiDAR setup on an incline, with loop closures occurring primarily when viewpoints are closely aligned. Right: Forest of Dean - flatter terrain compared to Wytham, with a sparser plantation, allowing for loop closures to be captured at greater distances. }
%   \label{fig:exp_multi_mission}
% \end{figure*}


% \begin{table}[htbp]
%   \centering
%   \small
%   \begin{tabular}{p{2cm}cccc}
%       \toprule
%       \multicolumn{1}{l}{loop closures} & \multicolumn{3}{c}{Dataset} \\
%       \multicolumn{1}{l}{distance range (m)} & Wytham & Evo & Forest of Dean \\
%       \midrule
%       0-5\,m &41 / 53\%  &83 / 78\%  &73 / 78\% \\
%       \midrule
%       5-10\,m &29 / 37\%  &19 / 18\% &15 / 16\%\\
%       \midrule
%       10-15\,m &8 / 10\%  &4 / 4\%   &6 / 6\% \\
%       \midrule
%       Total  & 78 / 100\%  & 106 / 100\%  & 94 / 100\% \\
%       \bottomrule
%   \end{tabular}
%   \caption{Offline Multi-mission map merging results corresponding to \figref{fig:exp_multi_mission}: Number and percentage of final inter-mission loop closures detected by distance between matched poses.}
%   %Setting rigorous thresholds on number of descriptors, SGV, pairwise consistency check and ICP registration allows robust loop-closure pairs to be found, with any loop-candidates more than 15m away rejected  
%   \label{tab:exp_offline_distance_table}
% \end{table}




% Fourth experiment: Relocalization 
\section{Relocalization} 
\label{sec:exp_relocalization}
% What is this experiment about?
This experiment showcases a demonstration of relocalization in a prior map. In this scenario, our system demonstrates the ability to continuously track the position of the mapping device within a prior SLAM map once an initial loop closure is established. Unlike the multi-mission SLAM use case, the prior map is now fixed as ground truth. To reiterate - the prior map (in green tree point clouds in \figref{fig:relocalization_demo}) is made up of individual scans with a descriptor rather than a single giant point cloud. We set the pairwise consistency threshold to $\sim$\SI{10}\,cm to enable consistent relocalization only within centimeter level of error. \vspace{5pt}
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.65\linewidth]{pics/exp_4_relocalization_demo.png}
  \caption{Demonstration of relocalization capability. The LiDAR sensor (illustrated by large marker) is relocalized in a prior map (dark brown). We render a virtual view of the forest digital map synchronized with images from our camera (up right image). The virtual tree models were generated by fitting cylindrical shapes to individual trees in the point cloud data, as described in \cite{freißmuth2024arxiv}. Red arrow shows a successful localization at that pose.}
  \label{fig:relocalization_demo}
\end{figure}

\noindent\textbf{Forest Surveying Demonstration}\hspace{0.5em}
\figref{fig:relocalization_before_after} present illustrative examples of this demonstration, where the quadruped robot is localized with respect to a prior SLAM map generated using a backpack LiDAR system. Drift accumulated by the robot was corrected by finding loop candidates in the prior map of individual scans as shown in \figref{fig:relocalization_before_after}. The left image shows the incorrect position of virtual tree model due to incorrect state estimate in odometry system. After relocalization, the virtual tree model is rendered again at the correct relocalized position. 

Overall, this capability enables the real-time rendering of a virtual forest map overlaid with associated data, such as Diameter at Breast Height (DBH) and species information, onto the camera images. Such feedback is highly beneficial for tasks such as taking forest inventories by foresters or enabling autonomous harvesting. \vspace{1pt}
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.9\linewidth]{pics/exp_4_relocalization_before_after3.pdf}
  \caption{Demonstration of relocalization of a quadruped robot before and after. Left image shows incorrect position of virtual tree model due to drift accumulated in odometry. Right image shows correct position of virtual tree model after relocalization.}
  \label{fig:relocalization_before_after}
\end{figure}

\noindent\textbf{Relocalization Failure}\hspace{0.5em}
In the relocalization scenario, relocalizing into an incorrect candidate leads to a sudden jump in current position (shown in left image in \figref{fig:relocalization_pairwise_cycle_consistency}). This is easily detected by checking pairwise cycle consistency between map-base $\Delta\mathbf{T}_{\M\B}$ and odometry-base frame $\Delta\mathbf{T}_{\Odo\B}$, and effectively prevent the relocalization failure by \SI{50}{\percent}. \figref{fig:relocalization_pairwise_cycle_consistency} shows an example of incorrect localization with an incorrect loop candidate (Left). Right image shows pairwise cycle consistency verification filtering out incorrect loop candidate.
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.9\linewidth]{pics/exp_4_relocalization_pairwise_before_after4.pdf}
  \caption{Left: relocalization failed due to incorrect loop candidate. Right: after filtering out incorrect loop candidate by pairwise cycle consistency checking.}
  \label{fig:relocalization_pairwise_cycle_consistency}
\end{figure}

% \subsection*{Time \& Distance to relocalize}
% We checked how long it takes to relocalize and how far the robot can move before relocalization fails.
%%%%%%%%%%%%%%%%%%%%%%%%

\section{Parameter analysis \& Computational Analysis}
In this section, we will discuss our final verification step of the ICP inlier-based check in more detail. We will also provide a brief computational analysis of the system, including runtime and memory consumption. \vspace{5pt}
\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\linewidth]{pics/exp_4_ablation_icp_inliers_4cm}
  \caption{Analysis of final ICP registration check. X-axis shows the distribution of loop-candidates by distance after ICP.
  Y-axis shows ICP correction error w.r.t. the coarse-registration from RANSAC. Color indicates the number of ICP inliers,  30 iterations and RMSE= 0.01m, where clouds are cropped 50 by 50m, then downsampled to 20k points.}
  \label{fig:icp_inliers}
\end{figure}

\noindent \textbf{Study of ICP inlier-based check}\hspace{0.5em} Our final experiment investigates the effect of the ICP inlier-based check on loop closure integration within the final pose graph optimization. Any incorrect loop closures should never be introduced into the optimized pose graph. We will consider this in the context of the online SLAM scenario. 

\figref{fig:icp_inliers} illustrates the corrections (on top of the initial transformation prior) as estimated by the ICP registration at various distances. Additionally, the figure color-codes the points based on the number of inlier points obtained during the registration process, with blue indicating a large number of inliers and red indicating a smaller number.
Our observation suggests that loop closures occurring more than 10\,m apart, which also propose a substantial transformation correction often have fewer inlier ICP points and are thus less reliable.
Based on this analysis, we need to establish an inlier threshold to ensure that corrections are limited to ICP corrections of less than 1 meter (shown in dotted red line). We will further discuss how to set this threshold in the following section.
\vspace{7pt}

\noindent\textbf{Setting ICP inlier thresholds} \hspace{0.5em} The ICP inlier threshold is the minimum number of points required for fine registration loop candidates. Only if the number of inliers turned out to be higher than a threshold will we accept the loop closure candidate. 
The ICP threshold should be fine-tuned to $\sim$ 3k-5k points depending on the LiDAR setup and forest environments. There is trade-off between the maximum baseline distance and the robustness of the loop-closure as shown in \figref{fig:icp_inliers_num}. For an example, in the Evo dataset, we set the threshold to 3k points, whereas in the Wytham Woods, we set the higher threshold to 4k-5k points. \vspace{7pt}
 \begin{figure}[htbp]
  \centering
  \includegraphics[width=0.99\linewidth]{pics/exp_4_icp_inliers_num4.pdf}
  \caption{Loop closure distribution by distance at various ICP inlier thresholds. Blue lines are accepted loop candidates, and red lines are rejected candidates. A stricter (higher) ICP inlier threshold will provide more robust loop closures, but the baseline distance range will be shorter, whereas lower ICP inliers will allow loop closures with a larger baseline distance, but there is an increased chance of getting false positive loop candidates.}
  \label{fig:icp_inliers_num}
\end{figure}
% What is the interpretation of the figure?
% Alongside \figref{fig:exp_2_2_loop_closure_histograms}, further analysis has been done how robust the loop-candidates are. 
% \figref{fig:ablation_icp_inliers} shows that under 10m distance, ICP inliers are high as over 4k points, and correction error is below 1m. However, the distribution of loop-candidates start to diverge significantly after 10m: correction error no longer bounds to 1m and the number of inliers are much less than 4k points. 
% Setting a low ICP inlier threshold will provide far distance loop-closures, but there is a chance of getting False Positives.

\noindent{\textbf{Runtime Analysis}}\hspace{0.5em} Currently the system requires a GPU for descriptor extraction. The system runs at 0.73 Hz on a laptop with an Intel i7-10750H CPU and an NVIDIA RTX A3000 GPU. The processing time for the top-1 loop closure candidate detection is shown in \tabref{tab:my-table}. The descriptor extraction and RANSAC featuring matching are the most time-consuming process. While these results are specific to the laptop configuration, a rate close to 1 Hz is sufficient for real-time applications. \vspace{1pt}
\begin{table}[htbp]
  \centering
  \small
  \begin{tabular}{@{}llllll@{}}
  \toprule
  \textbf{Process} & \textbf{Preprocessing} & \textbf{Descriptor} & \textbf{SGV} & \textbf{RANSAC} & \textbf{Total} \\ \midrule
  \textbf{Avg. Time (s)} & \multicolumn{1}{c}{0.015} & \multicolumn{1}{c}{0.09} & \multicolumn{1}{c}{0.001} & \multicolumn{1}{c}{1.1} & \multicolumn{1}{c}{1.3 /0.73 Hz} \\ % Centered second row
  \bottomrule
  \end{tabular}
  \caption{Avg. processing times for various tasks. The most time-consuming process is RANSAC-based feature matching. The system runs at 0.73 Hz.}
  \label{tab:my-table}
\end{table}

\noindent \textbf{Memory Consumption}\hspace{0.5em} The global descriptor has a dimensionality of (1,1028), requiring 8 bytes of memory, while the local descriptor, with dimensions (N, 256) (where N is the number of keypoints), consumes approximately 2KB of memory each. GPU memory usage, primarily dominated by local descriptors, totals around 2GB for mapping a typical single mission comprising about 1000 scans.
\vspace{7pt}

\noindent \textbf{Voxel Size}\hspace{0.5em} During preprocessing, voxelizing input point clouds is essential for utilizing \emph{MinkowskiEngine~\cite{choy20194cvpr}, SparseTorch~\cite{tang2023MICRO} with CUDA}. The voxel size significantly impacts model performance. Since both Logg3dNet and EgoNN are trained on Wild-Place dataset, which is different from our dataset in terms of density and range of LiDAR point clouds, we empirically identified the optimal voxel size between \SIrange{0.1}{1.0}{\meter} through direct experimentation on our dataset. Tab.~\ref{tab:voxel_size} shows that optimal voxel sizes are \SI{0.1}{\meter} and \SI{0.6}{\meter} for Logg3dNet on Evo dataset. Since the difference is not significant, after considering we decided to use voxel size of \SI{0.6}{\meter} considering computational efficiency.\\

\begin{table}[htbp]
  \centering
  \small
  \begin{tabular}{p{2cm} *{6}{c}}
      \toprule
      \multicolumn{1}{l}{Testing} & \multicolumn{6}{c}{Voxel size (cm)} \\
      \cmidrule{2-7}
      \multicolumn{1}{l}{Datasets} & 10 & 20 & 40 & 60 & 80 & 100 \\
      \midrule
      Evo-12 &\textbf{0.89} &0.79 &0.77 &\textbf{0.86} &0.79 &0.78 \\
      \addlinespace % Add space between rows
      Evo-16 & \textbf{0.74} & 0.66 & 0.66 & \textbf{0.66} & 0.64 & 0.63 \\
      \addlinespace % Add space between rows
      Evo-18  &0.71 & 0.75 & \textbf{0.75} & \textbf{0.76} & 0.73 & 0.71 \\
      \bottomrule
  \end{tabular}

  \caption{$F{1}_{max}$ score of Logg3dNet with different voxel sizes on Evo dataset. }
  \label{tab:voxel_size}
\end{table}

  
% \textbf{LI-OSAM Odometry System}\hspace{0.5em} We plan to test \emph{Place Recognition Server} with other LiDAR-intertial odometry systems such as LIOSAM~\cite{shan2020iros} to evaluate the robustness of the system in different environments. LIOSAM is a LiDAR-intertial odometry system that can provide accurate odometry information in various environments, including dense forests. We will evaluate the performance of the system with LIOSAM in the future.

