\chapter{Conclusion}
\label{chap:conclusion}

In this paper, we conducted extensive testing of LiDAR place recognition systems in dense forest environments. We presented a place recognition and verification system that leverages three stages of loop-candidate verification: at the global descriptor-level, local feature-level, and fine point cloud level. These place recognition modules were seamlessly integrated into a pose graph SLAM system and evaluated across three distinct scenarios: online SLAM, offline multi-mission SLAM, and relocalization. Our experiments provide further insights on the performance of currently available LiDAR-based place recognition methods in dense forests. Further, they demonstrate different integration cases to achieve 6-DoF localization, opening future applications for forest inventory, inspection, and autonomous tasks.

% This thesis has studied the navigation problem for legged robots through four contributions that exploit their unique capabilities. The systems presented faced the problem from different perspectives: sensing modalities, testing environments, and real-world applications. All the systems and algorithms developed in this thesis have been integrated on real robots, and tested in closed-loop autonomy experiments.

% In this last chapter, I will present a critical discussion on what was done, what was learned, and how we can improve it in the future.

% \section{Achievements and Limitations}
% First, I will discuss the contributions presented in this thesis, complementing the ideas shared at the end of each chapter, and providing additional connections between the different systems.

% \paragraph{Localisation} In \chapref{chap:visual-localisation}, I presented a \gls{vtr} system that enabled the practical deployment of a legged robot in industrial facilities. The system effectively addressed the navigation problem by closing the loop between the topo-metric representation and the locomotion controller, which was demonstrated through different real-world experiments. The other important contribution of this work was studying the uncertainty of vision-based localisation, given by the negative entropy, and using this information for decision making (camera selection) in subsequent deployments.

% When we talk about legged localisation, the challenges are not so different from any other robotic platform.
% I argue that localisation systems \emph{per se} do not require legged information to succeed, and most of the challenges depend on environment and sensing instead. In \chapref{chap:visual-localisation} and \chapref{chap:local-planning} I used vision, as it was more suitable for path following in narrow environments, though in \chapref{chap:autonomous-forest-inventory} I relied on a \gls{lidar} \gls{slam} system instead, as the environment provided enough geometric features to localise reliably; none of them required to introduce any aspects unique to legged platforms as part of the localisation process. In contrast, these aspects become highly relevant in scene representations used for planning through concepts such as traversability, which I discuss below.

% \paragraph{Local Planning} \chapref{chap:local-planning} introduced a reactive local planning framework to achieve safe navigation, motivated by challenges we observed in previous \gls{vtr} deployments. The local planner enabled the \gls{vtr} system presented in \chapref{chap:visual-localisation} to safely navigate in more complex environments, and react to under local changes found along the path. It also demonstrated competitive performance compared to other local planning approaches based on potential fields and motion primitives.

% This work explored the idea of combining different scene representations to generate reactive motion, instead of using a single occupancy-based representation.
% %In general it is assumed that a single representation exists (occupancy grid, voxel map, cost map, \glspl{sdf}), which is then used by a local planning approach such as the ones we presented in \secref{sec:algorithms-navigation}. By generating different intermediate representations that addressed specific tasks (e.g. avoiding obstacles, approaching the goal), it was possible to explicitly leverage them to achieve the desired motion in a modular way.
% Another important aspect of this contribution is that it became a core component in all the subsequent developments and field deployments showed in \chapref{chap:traversability-learning} and \chapref{chap:autonomous-forest-inventory}. 

% However, there are limitations related to its traditional local planning nature. The approach requires a local map, so its performance is limited by the representation and its capacity to encode the actual robot's capabilities, which I address in \chapref{chap:traversability-learning}. On the other hand, local planners are generally designed to avoid collisions. However, when navigating in natural environments  (e.g \chapref{chap:autonomous-forest-inventory}), collisions might be inevitable due to sensing and state estimation errors, or limitations of the scene representation (e.g. discretisation). I discuss this further in the future directions.

% \paragraph{Traversability Learning} \chapref{chap:traversability-learning} presented an online learning approach to determine which areas could be traversed by a legged robot, without any prior information. This work was motivated by the necessity to encode the robot's capabilities in the local navigation map in a practical way. Previous approaches required extensive expert tuning, massive datasets, or complex labeling solutions. Instead, we proposed an approach that supervised the data and learned a neural model while the robot operated.

% A key idea of this work was relying on deep neural models pre-trained in a self-supervised manner (foundation models). This enabled us to release the neural model from learning \emph{everything} from scratch \cite{Bradley2015, Wellhausen2019,Gasparino2022}, and instead used the pre-trained features to focus on learning the relevant task. I believe that such models have great potential for other robotics applications, so I will give greater discussion of this topic later in this chapter.

% The main limitations of this approach concern the design decisions and hardware limitations. The use of superpixels to reduce computational complexity, the coarse footprint-based self-supervision approach, and the local map integration via-raycasting are the main issues, reducing the fidelity of the estimated traversability score.

% \paragraph{Forestry Applications} Lastly, \chapref{chap:autonomous-forest-inventory} introduced a real application of the aforementioned methods for forestry tasks. I presented a solution based on three components, including a consistent state estimation system, a multi-levelled autonomy approach, and a forestry pipeline that operated on point cloud data.

% We executed five autonomous missions on different forest areas in Finland. We demonstrated that our solution enabled a legged platform to autonomously navigate within the forest, and collect valuable 3D data for futher processing. These experiments also allowed to contextualise the research developed in the previous chapters. In particular, the local planner from \chapref{chap:local-planning} was a key component in the autonomy system, while the traversability estimation system from \chapref{chap:traversability-learning} has the potential to improve performance in future deployments.

% The solution is currently under active development, and I plan to further improve the solution using the insights gained in the field deployments reported.

% \section{Lessons Learned}
% During this research I also learned many general lessons on robotic system design and deployment, as well as the navigation problem. The goal of this section is to provide a broader perspective on important challenges I recognise in the field.

% \paragraph{Representations} The idea of \emph{representations for robotics} is present across the different chapters of this thesis. \emph{Good} representations can massively simplify the solutions we design, allowing us to focus on the important aspects of the problem.

% In this thesis I adopted a topological approach to represent the robot missions and global plans, both in the \gls{vtr} system as well as the \emph{survey plan} used for the legged forester (\chapref{chap:autonomous-forest-inventory}). Metric information was only used for visual localisation against a reference node in a topo-metric map (\chapref{chap:visual-localisation}), or local elevation maps for planning (\chapref{chap:local-planning}). 

% Similarly, the learned pre-trained features obtained from large neural models have been effective for a variety of tasks, such as object detection, place recognition, and panoptic segmentation. In \chapref{chap:traversability-learning} we used them for traversability learning, releasing us from learning the features relevant for this task by ourselves.

% A good representation can encode meaningful information about the task. For example, in \chapref{chap:local-planning}, we used a \gls{gdf} to encode the navigation information needed to reach the goal. This relates to the ideas of \emph{navigation functions} \cite{Koditschek1987}, which enable robots to navigate, collision-free, just by implementing a control law that follows the gradient of the navigation function. This supposes that the navigation problem can be solved, in principle, just by having the appropriate representation. More recent works have also explored similar ideas for manipulation \cite{Pari2022}, navigation \cite{Frey2022a,Huang2023}, or semantic understanding \cite{Peng2023,Jatavallabhula2023}.

% \paragraph{Hierarchical Architectures} When developing robotic solutions, one common desire is designing solutions that solve \emph{all the problems}. For example, local planners \emph{must} guide a robot through any environment without collisions to be successful. Similarly, localisation systems \emph{must} determine the robot's pose at any location regardless of the conditions.

% However, when developing complex, integrated systems, it might be preferred to have modules that are \emph{aware of their own limitations}. Similar ideas have been explored in the past, namely as elastic bands (coupling local planning and control)~\cite{Quinlan1993}, subsumption architectures (layered decision-making modules)~\cite{Brooks1986}, as well as real-world deployments in the \gls{darpa} challenges \cite{Agha2021,Tranzatto2023,Kottege2023}.
%  In \chapref{chap:autonomous-forest-inventory}, instead of designing a perfect local planning solution able to deal with the any kind of environments, we implemented a strategy to identify when it was struggling to move forward. This information was reported to the upper level of the autonomy system, which instead selected a different local goal to continue the mission.

% While these hierarchical interactions are common in control and planning, they have been less explored for state estimation solutions. \emph{Active perception}~\cite{Bajcsy2018} and \emph{next-best-view}~\cite{Bircher2016} approaches are examples that improve perception by decision-making and planning in a proactive fashion. The active camera selection system presented in \chapref{chap:visual-localisation} also relates to these ideas, as it anticipated perception degradation along the path using the learned \glspl{cpm}. 

% Uncertainty estimates produced by odometry and \gls{slam} systems are also a mechanism to report potential issues to other modules in the stack. However, as they are unable to provide guarantees, current \emph{certification} methods aim to address these limitations \cite{Carlone23}.

% \paragraph{Fundamental Ideas} The last lesson regards the fundamental underlying ideas of the robotics toolbox. Optimisation and geometry are the backbone of many robotics problems, and identifying the connections between apparently unrelated problems can provide novel solutions and valuable insights. 

% The duality of the \glsfirst{ls} problem in visual localisation and optimisation-based planning, motivated the use of \glspl{rmp} in \chapref{chap:local-planning}. While the localisation problem is originated from a probabilistic perspective~\cite{Dellaert2017}, \glspl{rmp} are motivated by purely geometric principles~\cite{Ratliff2018}. These dualities have been previously discussed in the past by some authors, for example see \textcite{Todorov2008,Toussaint2017}.

% Similarly, in \chapref{chap:traversability-learning} our online self-supervision scheme was motivated by the sliding window-based approaches to state estimation \cite{Sibley2010}. However, we did not formulate the learning problem as a windowed optimisation. Recent works have explored a tighter relationship of state estimation and learning~\cite{Pineda2022}, for example using the state estimation problem as self-supervision \cite{Yoon2021}.

% \section{Future Directions}
% To conclude, I present future directions for legged navigation research, that I hope can motivate future projects in the field.

% \paragraph{Pre-trained Models} Large pre-trained (foundation) models have revolutionised robotics in the last two years. I expect that this topic will continue trending in the short term, as robotics presents specific challenges that go far beyond the training domain of such models. In \chapref{chap:traversability-learning}, we used the DINO-ViT model~\cite{Caron2021} to obtain expressive features for traversability learning. While these features were trained in a self-supervised way to learn joint embeddings in spite of image augmentations, they are able to represent high-dimensional semantic features of the images.

% My personal view is that the effect of these pre-trained features in the robotics community is like SIFT \cite{Lowe2004}: While we \emph{might} not need to fully understand the meaning of the SIFT descriptors, we know they can be used to develop \gls{sfm} solutions~\cite{Schonberger2016}, visual odometry and \gls{slam} systems~\cite{MurArtal2015}, as well as place recognition methods based on feature quantisation \cite{Cummins2008,GalvezLopez2012}. Pre-trained models are being used for semantic understanding, visual-language navigation, as well as place recognition, and I foresee more applications to come in the following years.

% For navigation, these large pre-trained models can contribute with general priors that require some kind of expressive features. For example, we observed lighting robustness of these features in the experiments in \chapref{chap:traversability-learning}, which can benefit localisation tasks. Similarly, models like CLIP~\cite{Radford2021} can provide semantic understanding via natural language, which can support better interfaces and representations for navigation \cite{Jatavallabhula2023}. However, it remains to be seen how these principles apply to other sensor modalities, such as \gls{lidar}, as well as the conditions under which the datasets they were trained on break, especially for outdoor applications.

% \paragraph{Interaction} As previously mentioned, navigation is usually framed in a way that the robot must avoid contact with the environment, because it can either damage itself or the surroundings. For robots to succeed at navigating in the wild, we should free them from this constrain and enable some haptic interaction with the environment \cite{Qian2020,Wijmans2023}.

% Enabling this on legged robots is a manifold problem: it involves the design of new sensing capabilities (e.g. artificial skin, touch and temperature sensing), new estimation algorithms and controllers (to take into account this input for state estimation and control policies), as well as system architectures (what to do with this new information and what behaviours are available?).

% For legged navigation, I would argue that interactions should be handled at the locomotion level, similarly to the locomotion policies developed by \textcite{Lee2020,Miki2022a,Kumar2021,Choi2023}. However, instead of operating with nominal trotting gaits, they should enable changes in the gait (e.g. walk slowly) by leveraging feet and body contact information, as well as uncertainties about the environment. Ideally, they should also introduce semantic information from vision to improve performance on natural environments. Locomotion policies are either blind \cite{Lee2020,Choi2023} or disregard exteroceptive data when unreliable \cite{Miki2022a}. Semantics can provide additional cues about the terrain, which could improve performance to walk in the forest, similarly to the traversability learning approach in \chapref{chap:traversability-learning}. However, it is an open question how to train such policies combining simulation and real data.

% With the locomotion policies becoming more capable, the higher level modules will get simpler. If the policies are able to deal with the short-range neighborhood (e.g. \SI{1}{\meter} radius), they will be solving part of the local navigation, as it has been shown for structured environments \cite{Rudin2022}. This suggest that instead of having a explicit traversability estimation and local planning modules we could have a heading controller to guide local navigation instead, such as BADGR \cite{Kahn2021}. Nevertheless, I believe that such policies should not only provide an action to execute, but also feedback on their behaviour to be integrated into larger autonomy stacks.

% \paragraph{Operation in Natural Environments} As legged robots are becoming more affordable, novel applications will be unlocked in new domains. Legged robots are a versatile platform, that can enable automated and systematic monitoring of natural traits. In \chapref{chap:autonomous-forest-inventory} we demonstrated an application for autonomous surveying and forest inventory. However, this use-case considered single, independent exploration missions to collect data from a determined area in the forest.

% Long-term autonomous operation with legged robots has been demonstrated for monitoring in offshore and other industrial facilities \cite{BostonDynamics,Anybotics}. As the environments are structured and the operating conditions well-defined, they present the ideal scenario for their extended deployment. However, long-term deployments in natural environments have not been extensively explored.

% Wildfire prevention, biodiversity monitoring, or general scientific data acquisition are potential areas where legged robots can contribute \cite{Dunbabin2012}. For such tasks, robots might perform periodic data collection missions, spread across several weeks, months, or even years. This imposes several multiple challenges for robotics as a field.

% Robot hardware must be robust, efficient and compliant with the environment. On the other hand, state estimation must be reliable under different environmental conditions, lighting, seasons and also failures. However, it might not be necessary for this to be millimiter-accurate. Navigation and planning systems must be primarly safe, to make sure the robot does not get damaged but it does not harm the environment during operation either. 

% Lastly, they need to comply with the specifications and requirements of the task. Because in the end is not about the robots, but the opportunities they offer to transform humanity for better.
